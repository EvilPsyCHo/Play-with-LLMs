{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀Mixtral-8x7B-instruct实现ReAct Agent并支持工具调用\n",
    "\n",
    "![](../assets/simple-react.gif)\n",
    "\n",
    "在开始之前，如果你还不了解如何利用grammar让LLMs按照你要求的格式输出，点击[mistral-stable-output-JSON-format](./mistral-stable-output-JSON-format.ipynb)查看如何控制模型输出格式。\n",
    "参考：\n",
    "- https://github.com/Maximilian-Winter/llama-cpp-agent\n",
    "- https://www.reddit.com/r/MistralAI/comments/191wg3i/react_prompting_mistral_or_mixtral/\n",
    "- https://pastebin.com/a94xp56b\n",
    "- https://pastebin.com/H3a9HiHw\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*adwhd8hmwcCAYTZNMiSAxA.png)\n",
    "\n",
    "CoT让模型具备了问题分解与推理（？）能力，但受限于模型知识它不知道今天北京的天气，也不知道最新的新闻资讯，也无法进行复杂的数学元算。同时，一些复杂问题往往无法通过单轮的交互完成，模型往往需要进行多轮的信息收集、计算、工具调用才能得到合理答案。ReAct（Reasoning and Acting）是一个很好的解决方案，其模型交互过程如下：\n",
    "\n",
    "```text\n",
    "Question: 用户问题\n",
    "Assistant:\n",
    "  Thought: 思考\n",
    "  Action: 调用tool/function\n",
    "  Observation: 反馈执行结果\n",
    "  ...循环N次\n",
    "  Thought: Now, I know the final answer for this question.\n",
    "  Final Answer: 最终答案\n",
    "```\n",
    "\n",
    "一般我们需要在模型输出`Observation: `时打断模型，调用函数或工具API执行，并将结果拼接到`Observation: `后，否则模型会自己想象答案。\n",
    "\n",
    "为了确保模型了解所有可调用的函数或工具，在输入提示词（system 或 user）中需要需要告知模型的详细信息，比如：\n",
    "\n",
    "```text\n",
    "You are an AI agent capable of using a variety of functions to answer a question.\n",
    "\n",
    "{{func_desc}}\n",
    "\n",
    "Response using the follow format:\n",
    "\n",
    "Thought: think step by steps, how to solve the question, put your thought process here.\n",
    "Action: {\n",
    "    \"function\": $FUNCTION_NAME,\n",
    "    \"args\": $FUNCTION_ARGS,\n",
    "}\n",
    "Observation: function output\n",
    "...(this Thought/Action/Observation can repeat N times) \n",
    "Thought: Now I know the final answer.\n",
    "Final Answer: the final answer\n",
    "\n",
    "$FUNCTION_NAME is the name of function. $FUNCTION_ARGS is a dictionary input matching the requirement of function.\n",
    "\n",
    "<START>\n",
    "Question: {{question}}\\n\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_cuda_init: found 2 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n",
      "  Device 1: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama, LlamaGrammar\n",
    "model = Llama(\"/data/hf/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\", n_gpu_layers=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_weather(city: str):\n",
    "    \"\"\"A useful function to check the weather.\n",
    "    \n",
    "    Args:\n",
    "        city: the city where you want to check the weather\n",
    "    \"\"\"\n",
    "    if city == \"北京\":\n",
    "        return \"北京气温36度\"\n",
    "    elif city == \"巴黎\":\n",
    "        return \"巴黎气温24度\"\n",
    "    else:\n",
    "        return f\"{city}气温20度\"\n",
    "\n",
    "func_desc = \"\"\"function: search_weather\n",
    "  description: A useful function to check the weather.\n",
    "  args:\n",
    "    city (str): the city where you want to check the weather\n",
    "\"\"\"\n",
    "\n",
    "# from typing import List, Optional, Union, Dict\n",
    "# from llama_cpp_agent.gbnf_grammar_generator.gbnf_grammar_from_pydantic_models import generate_text_documentation, create_dynamic_model_from_function, generate_gbnf_grammar\n",
    "# func_desc = generate_text_documentation([create_dynamic_model_from_function(search_weather)], model_prefix=\"function\", fields_prefix=\"args\")\n",
    "# func_grammar = generate_gbnf_grammar(create_dynamic_model_from_function(search_weather), set(), dict())\n",
    "# print(func_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REACT_PROMPT = '''[INST] You are an AI agent capable of using a variety of functions to answer a question.\n",
    "\n",
    "### Accessable Function\n",
    "\n",
    "{{func_desc}}\n",
    "\n",
    "### Reponse Format\n",
    "Response using the follow format:\n",
    "\n",
    "Thought: think step by steps, how to solve the question, put your thought process here.\n",
    "Action:\n",
    "```json\n",
    "{\n",
    "    \"function\": $FUNCTION_NAME,\n",
    "    \"args\": $FUNCTION_ARGS\n",
    "}\n",
    "```\n",
    "Observation: function output\n",
    "...(this Thought/Action/Observation can repeat N times) \n",
    "Thought: I now know the final answer \n",
    "Final Answer: the final answer\n",
    "\n",
    "$FUNCTION_NAME is the name of function. $FUNCTION_ARGS is a dictionary input matching the requirement of function.\n",
    "\n",
    "<START>\n",
    "Question: {{question}} [\\INST]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import Dict, List\n",
    "import re\n",
    "import json\n",
    "\n",
    "def react_agent(model, question, function, function_desc, max_rounds=3):\n",
    "    # construct input prompt\n",
    "    print(f\"Question: {question}\")\n",
    "    prompt = REACT_PROMPT.replace(\"{{question}}\", question).replace(\"{{func_desc}}\", function_desc)\n",
    "    output = \"\"\n",
    "    try:\n",
    "        for i in range(max_rounds):\n",
    "            # Thought step\n",
    "            response = model.create_completion(prompt, stop=[\"Observation: \"], max_tokens=400)[\"choices\"][0][\"text\"]\n",
    "            output += response\n",
    "            print(response, end=\"\")\n",
    "            # If \"FinalAnswer\" in reponse, end react process\n",
    "            if \"Final Anwser:\" in response:\n",
    "                output += response\n",
    "                break\n",
    "\n",
    "            elif \"Action:\" in response:\n",
    "                args = json.loads(re.findall(\"```json([\\s\\S]*?)```\", response)[0].replace(\"\\n\", \"\").replace(\" \", \"\"))\n",
    "                obs = function(**args[\"args\"])\n",
    "                obs = f\"Observation: {obs}\" + \"\\nThought: \"\n",
    "                output += obs\n",
    "                prompt += obs\n",
    "                print(obs, end=\"\")\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "    return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 北京和巴黎现在哪个地方更热？\n",
      "Thought: The question asks for a comparison of the current temperature in Beijing and Paris. I can use the search\\_weather function to find out. I will need to call the function twice, once for each city.\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "    \"function\": \"search_weather\",\n",
      "    \"args\": {\n",
      "        \"city\": \"北京\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "Observation: 北京气温36度\n",
      "Thought:  To answer this question, I need to check the current temperature in Beijing and Paris. I already know the current temperature in Beijing is 36 degrees. Now, I should get the temperature in Paris.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "    \"function\": \"search_weather\",\n",
      "    \"args\": {\n",
      "        \"city\": \"Paris\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "Observation: Paris气温20度\n",
      "Thought: 北京的温度比巴黎高, so I can answer the question now.\n",
      "Final Answer: 现在北京更热。"
     ]
    }
   ],
   "source": [
    "question = \"北京和巴黎现在哪个地方更热？\"\n",
    "output = react_agent(model, question, search_weather, func_desc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gomars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
