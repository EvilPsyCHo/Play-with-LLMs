{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Llama3-8b-Instruct React Agent Advanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kky/miniconda3/envs/gomars/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-02 16:49:30,840\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-02 16:49:32 config.py:407] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 16:49:34,363\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-02 16:49:35 llm_engine.py:79] Initializing an LLM engine with config: model='/data/hf/Meta-Llama-3-8B-Instruct', tokenizer='/data/hf/Meta-Llama-3-8B-Instruct', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-02 16:49:46 llm_engine.py:337] # GPU blocks: 12465, # CPU blocks: 4096\n",
      "INFO 05-02 16:49:47 model_runner.py:666] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-02 16:49:47 model_runner.py:670] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=1497972)\u001b[0m INFO 05-02 16:49:47 model_runner.py:666] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=1497972)\u001b[0m INFO 05-02 16:49:47 model_runner.py:670] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=1497972)\u001b[0m INFO 05-02 16:49:56 model_runner.py:738] Graph capturing finished in 9 secs.\n",
      "INFO 05-02 16:49:56 model_runner.py:738] Graph capturing finished in 9 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from llama_index.core.agent import ReActAgent\n",
    "llm = LLM(\n",
    "    model=\"/data/hf/Meta-Llama-3-8B-Instruct\",\n",
    "    trust_remote_code=True,\n",
    "    tensor_parallel_size=2,\n",
    ")\n",
    "tokenizer = llm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful Assistant named eric simon<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "who are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = tokenizer.apply_chat_template([{\"role\": \"system\", \"content\": \"You are a helpful Assistant named eric simon\"}, {\"role\": \"user\", \"content\": \"who are you?\"}], \n",
    "                              tokenize=False, add_generation_prompt=True)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt; Tool Name: search_weather\n",
       "Tool Description: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">search_weather</span><span style=\"font-weight: bold\">(</span>city_name: str<span style=\"font-weight: bold\">)</span> -&gt; str\n",
       "check real-time weather and temperature of a city\n",
       "Tool Args: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"object\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"properties\"</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"city_name\"</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"City Name\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"string\"</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"required\"</span>: \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"city_name\"</span><span style=\"font-weight: bold\">]}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "> Tool Name: search_weather\n",
       "Tool Description: \u001b[1;35msearch_weather\u001b[0m\u001b[1m(\u001b[0mcity_name: str\u001b[1m)\u001b[0m -> str\n",
       "check real-time weather and temperature of a city\n",
       "Tool Args: \u001b[1m{\u001b[0m\u001b[32m\"type\"\u001b[0m: \u001b[32m\"object\"\u001b[0m, \u001b[32m\"properties\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"city_name\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"title\"\u001b[0m: \u001b[32m\"City Name\"\u001b[0m, \u001b[32m\"type\"\u001b[0m: \u001b[32m\"string\"\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m\"required\"\u001b[0m: \n",
       "\u001b[1m[\u001b[0m\u001b[32m\"city_name\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from typing import Dict, List, Any, Sequence, Callable\n",
    "import re\n",
    "import json\n",
    "from rich import print\n",
    "\n",
    "\n",
    "REACT_PROMPT = '''You are an AI agent capable of using a variety of tools to answer question.\n",
    "\n",
    "You have access to the following tools:\n",
    "{{tools_desc}}\n",
    "\n",
    "### Reponse Format\n",
    "\n",
    "Response using the follow format:\n",
    "\n",
    "Thought: think step by steps, how to solve the question, put your thought process here.\n",
    "Action:\n",
    "```json\n",
    "{\n",
    "    \"tool\": $TOOL_NAME,\n",
    "    \"args\": $TOOL_ARGS\n",
    "}\n",
    "```\n",
    "Observation: tool output\n",
    "...(this Thought/Action/Observation can repeat N times until you get enough information to answer the question)\n",
    "Thought: I now know the final answer \n",
    "Final Answer: make sure output the final answer here\n",
    "\n",
    "$TOOL_NAME is the name of the tool. $TOOL_ARGS is a dictionary input matching the requirement of the tool.\n",
    "'''\n",
    "\n",
    "\n",
    "# copy from llama-index\n",
    "# get function tools description\n",
    "def get_react_tool_descriptions(tools: Sequence[BaseTool]) -> List[str]:\n",
    "    \"\"\"Tool.\"\"\"\n",
    "    tool_descs = []\n",
    "    for tool in tools:\n",
    "        tool_desc = (\n",
    "            f\"> Tool Name: {tool.metadata.name}\\n\"\n",
    "            f\"Tool Description: {tool.metadata.description}\\n\"\n",
    "            f\"Tool Args: {tool.metadata.fn_schema_str}\\n\"\n",
    "        )\n",
    "        tool_descs.append(tool_desc)\n",
    "    return tool_descs\n",
    "\n",
    "\n",
    "def search_weather(city_name: str) -> str:\n",
    "    \"\"\"check real-time weather and temperature of a city\"\"\"\n",
    "    return \"temperature 27, weather rain\"\n",
    "\n",
    "\n",
    "print(get_react_tool_descriptions([FunctionTool.from_defaults(search_weather)])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActOutputParser:\n",
    "    \"\"\"ReAct Output parser.\"\"\"\n",
    "\n",
    "    def parse(self, output: str):\n",
    "        if \"Final Answer:\" in output:\n",
    "            return self.extract_final_answer(output)\n",
    "\n",
    "        if \"Action:\" in output:\n",
    "            return self.extract_action(output)\n",
    "\n",
    "        raise ValueError(f\"Could not parse output: {output}\")\n",
    "    \n",
    "    def extract_action(self, input_text: str):\n",
    "        pattern = r\"Thought:([\\s\\S]*?)Action:([\\s\\S]*)\"\n",
    "        match = re.search(pattern, input_text)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not extract Thought/Action from input text: {input_text}\")\n",
    "\n",
    "        thought = match.group(1).strip()\n",
    "        action = match.group(2).strip()\n",
    "\n",
    "        json_block_pattern = \"```json([\\s\\S]*?)(```|$)\"\n",
    "        match = re.search(json_block_pattern, action)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not extract Action JSON block from input text: {action}\")\n",
    "        action_json = match.group(1).strip()\n",
    "        import dirtyjson\n",
    "        try:\n",
    "            action_json = dirtyjson.loads(action_json)\n",
    "        except:\n",
    "            raise ValueError(f\"Unable parse JSON from {action_json}\")\n",
    "        \n",
    "        import json\n",
    "        raw_message = json.dumps(action_json, indent=4)\n",
    "        return {\n",
    "            \"step\": \"reasoning_acting\", \n",
    "            \"content\": {\"thought\": thought, \"action\": action_json}, \n",
    "            \"raw_message\": input_text}\n",
    "\n",
    "\n",
    "    def extract_final_answer(self, response):\n",
    "        pattern = r\"\\s*Thought:([\\s\\S]*?)Final Answer:([\\s\\S]*?)(?:$)\"\n",
    "        match = re.search(pattern, response, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(\n",
    "                f\"Could not extract final answer from input text: {response}\"\n",
    "            )\n",
    "\n",
    "        thought = match.group(1).strip()\n",
    "        answer = match.group(2).strip()\n",
    "        raw_message = f\"Thought: {thought}\\nFinal Answer: {answer}\"\n",
    "        return {\n",
    "            \"step\": \"answer\", \n",
    "            \"content\": {\"thought\": thought, \"answer\": answer}, \n",
    "            \"raw_message\": response,\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "\n",
    "    def __init__(self, llm, tools: List[Callable], system_prompt: str=None, max_rounds: int=10, output_parser=None):\n",
    "        self.llm = llm\n",
    "        self.tokenizer = llm.get_tokenizer()\n",
    "        tools = [FunctionTool.from_defaults(fn=t) for t in tools]\n",
    "        self.tools = {f.metadata.get_name(): f for f in tools}\n",
    "        self.system_prompt = system_prompt or REACT_PROMPT\n",
    "        self.max_rounds = max_rounds\n",
    "        self.output_parser = output_parser or ReActOutputParser()\n",
    "        self.is_llama3 = \"<|eot_id|>\" in tokenizer.vocab\n",
    "    \n",
    "    def format_system_prompt(self):\n",
    "        tools_name = \", \".join([tool.metadata.get_name() for tool in self.tools.values()])\n",
    "        tools_desc = \"\\n\".join(get_react_tool_descriptions(self.tools.values()))\n",
    "        return self.system_prompt.replace(\"{{tools_desc}}\", tools_desc).replace(\"{{tools_name}}\", tools_name)\n",
    "\n",
    "    def generate(self, messages, stop=None, max_tokens=1024):\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        stop_token_ids = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")] if self.is_llama3 else [tokenizer.eos_token_id]\n",
    "        sampling_params = SamplingParams(max_tokens=max_tokens, stop=stop, stop_token_ids=stop_token_ids, temperature=0.)\n",
    "        model_output = llm.generate([prompt], sampling_params=sampling_params, use_tqdm=False)[0].outputs[0].text\n",
    "        return model_output\n",
    "        \n",
    "    def run(self, query, num_rounds=None, verbose=False):\n",
    "        # Initialization\n",
    "        num_rounds = min(num_rounds, self.max_rounds) if num_rounds else self.max_rounds\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.format_system_prompt()},\n",
    "            {\"role\": \"user\", \"content\": f\"{query}\"}\n",
    "            ]\n",
    "        trajectory = [{\"step\": \"query\", \"content\": query, \"raw_message\": query}]\n",
    "\n",
    "        # query\n",
    "        if verbose:\n",
    "            print(f\"[green3]Query[/green3]\")\n",
    "            print(query)\n",
    "        for _ in range(1, 1+num_rounds):\n",
    "            model_output = self.generate(messages, stop=\"Observation:\")\n",
    "            messages.append({\"role\": \"assistant\", \"content\": model_output})\n",
    "            try:\n",
    "                step_state = self.output_parser.parse(model_output)\n",
    "            except Exception as e:\n",
    "                return {\"response\": str(e), \"trajectory\": trajectory, \"successful\": False}\n",
    "            if verbose:\n",
    "                print(f\"[green3]{step_state['step']}[/green3]\")\n",
    "                print(step_state[\"raw_message\"])\n",
    "            trajectory.append(step_state)\n",
    "            if step_state[\"step\"] == \"reasoning_acting\":\n",
    "                func = self.tools[step_state[\"content\"][\"action\"][\"tool\"]]\n",
    "                args = step_state[\"content\"][\"action\"][\"args\"]\n",
    "                try:\n",
    "                    observation = func(**args).content\n",
    "                except Exception as e:\n",
    "                    return {\"response\": str(e), \"trajectory\": trajectory, \"successful\": False}\n",
    "                if verbose:\n",
    "                    print(f\"[green3]observation[/green3]\")\n",
    "                    print(observation)\n",
    "                trajectory.append({\"step\": \"observation\", \"content\": observation, \"raw_message\": observation})\n",
    "                messages.append({\"role\": \"user\", \"content\": f\"Observation: {observation}\"})\n",
    "            elif step_state[\"step\"] == \"answer\":\n",
    "                return {\"response\": step_state[\"content\"][\"answer\"], \"trajectory\": trajectory, \"successful\": True}\n",
    "        return {\"response\": \"Maximum number of iterations exceeded\", \"trajectory\": trajectory, \"successful\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two integers and returns the result integer\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divides two integers and returns the result integer\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "tools = [multiply, add, subtract, divide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700\">Query</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;40mQuery\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> * <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> *<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "What is \u001b[1m(\u001b[0m\u001b[1;36m121\u001b[0m + \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m * \u001b[1;36m5\u001b[0m *\u001b[1;36m100\u001b[0m?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700\">reasoning_acting</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;40mreasoning_acting\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Thought: First, I need to calculate the expression inside the parentheses, which is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Then, I need to \n",
       "multiply the result by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, and finally, I need to multiply the result by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>.\n",
       "\n",
       "Action:\n",
       "```json\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"tool\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"add\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"args\"</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"a\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"b\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Thought: First, I need to calculate the expression inside the parentheses, which is \u001b[1;36m121\u001b[0m + \u001b[1;36m2\u001b[0m. Then, I need to \n",
       "multiply the result by \u001b[1;36m5\u001b[0m, and finally, I need to multiply the result by \u001b[1;36m100\u001b[0m.\n",
       "\n",
       "Action:\n",
       "```json\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"tool\"\u001b[0m: \u001b[32m\"add\"\u001b[0m,\n",
       "    \u001b[32m\"args\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"a\"\u001b[0m: \u001b[1;36m121\u001b[0m, \u001b[32m\"b\"\u001b[0m: \u001b[1;36m2\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "```\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700\">observation</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;40mobservation\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m123\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700\">reasoning_acting</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;40mreasoning_acting\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Thought: Now that I have the result of the addition, I need to multiply it by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>.\n",
       "\n",
       "Action:\n",
       "```json\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"tool\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"multiply\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"args\"</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"a\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"b\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Thought: Now that I have the result of the addition, I need to multiply it by \u001b[1;36m5\u001b[0m.\n",
       "\n",
       "Action:\n",
       "```json\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"tool\"\u001b[0m: \u001b[32m\"multiply\"\u001b[0m,\n",
       "    \u001b[32m\"args\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"a\"\u001b[0m: \u001b[1;36m123\u001b[0m, \u001b[32m\"b\"\u001b[0m: \u001b[1;36m5\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "```\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700\">observation</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;40mobservation\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">615</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m615\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700\">reasoning_acting</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;40mreasoning_acting\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Thought: Now that I have the result of the multiplication, I need to multiply it by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>.\n",
       "\n",
       "Action:\n",
       "```json\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"tool\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"multiply\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"args\"</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"a\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">615</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"b\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Thought: Now that I have the result of the multiplication, I need to multiply it by \u001b[1;36m100\u001b[0m.\n",
       "\n",
       "Action:\n",
       "```json\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"tool\"\u001b[0m: \u001b[32m\"multiply\"\u001b[0m,\n",
       "    \u001b[32m\"args\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"a\"\u001b[0m: \u001b[1;36m615\u001b[0m, \u001b[32m\"b\"\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700\">observation</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;40mobservation\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m61500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700\">answer</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;40manswer\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Thought: I have now calculated the final result, which is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61500</span>.\n",
       "\n",
       "Final Answer: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Thought: I have now calculated the final result, which is \u001b[1;36m61500\u001b[0m.\n",
       "\n",
       "Final Answer: \u001b[1;36m61500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = ReActAgent(llm, tools)\n",
    "response = agent.run(\"What is (121 + 2) * 5 *100?\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m61500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gomars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
